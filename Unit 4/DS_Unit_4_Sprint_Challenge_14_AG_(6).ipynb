{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "be4be556e732c48fd93c858856029fbd",
          "grade": false,
          "grade_id": "cell-89fa18eaaf69c47f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "E4LZY6Y_mH8m"
      },
      "source": [
        "\n",
        "## *Data Science Sprint 14*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron (i.e. Neural Network)\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)\n",
        "\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "80b53343211b3ec6d5a7d63295854bf8",
          "grade": false,
          "grade_id": "cell-d282993617980687",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Ric7EgWhmH8q"
      },
      "source": [
        "## Part 0: Import Packages\n",
        "\n",
        "For this notebook, you will need to import: \n",
        "\n",
        "- `numpy`\n",
        "- `pandas`\n",
        "- `matplotlib`\n",
        "- `StandardScaler`\n",
        "- `tensorflow`\n",
        "- `keras`\n",
        "- `Sequential`\n",
        "- `Dense`\n",
        "- `GridSearchCV`\n",
        "- `KerasClassifier`\n",
        "\n",
        "You will also need to install `!pip install mlxtend` if you are working on a notebook. **Be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "84e2be87dc9ad72d512f91665cd5c2c3",
          "grade": false,
          "grade_id": "cell-22a157c6967388c1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "pu9BE3r_mH8q"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDHSnnmMVwd0",
        "outputId": "7eed7511-5ab3-4d91-85c1-6cb9f886f9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "111db249c60793826d6f0ef305781ea4",
          "grade": true,
          "grade_id": "cell-ee3f0bbd9fd79ceb",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JcuRhka-mH8r"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert pd.__package__ == 'pandas'\n",
        "assert GridSearchCV.__module__ == 'sklearn.model_selection._search'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9b2b58b20b3c75b2f8ac786fda7fa46d",
          "grade": false,
          "grade_id": "cell-6adae65226f09553",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wLP2hgQBmH8r"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## Part 1: Review: \n",
        "### Defining Neural Networks \n",
        "\n",
        "\n",
        "- **Neuron:** An individual node of a neural network. It takes in a combination of inputs and weights, multiplies them together, adds a bias term, and then passes the result through an activation function. The result of this process is what the neuron will pass onto the subsequent layer. Neural Network nodes are modeled after the neurons in the human brain. They have a activation function that decides how much signal to pass onto other neurons. In the human brain there is an electrochemical threshold that decides when and when not to fire. \n",
        "- **Input Layer:** The first layer of nodes in a neural network. This layer receives values from our dataset and combines them with the weights and biases before passing the data to the first hidden layer. \n",
        "- **Hidden Layer:** The middle layers of a neural network that are not the input layer or output layer. These nodes perform the same operations as all others, but are not directly accessible during training. Having multiple hidden layers in a neural network architecture is what determines the designation of \"Deep Learning.\"\n",
        "- **Output Layer:** The final layer of our neural network, the output layer outputs our model's final predictions. For regression problems this is a single node that outputs a continuous value. For binary classification, it is a single node that outputs a probability between 0 & 1, and for multi-class implementations the output layer typically includes a node for each of the classes that we are trying to predict.\n",
        "- **Activation:** Activation functions express how strongly or weakly signal should be passed to the next layer given the weighted sum of the previous input + a bias term. The resulting output is usually referred to as an 'activation'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nidKQL5mH8s"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## Part 2. Simple Perceptron\n",
        "\n",
        "For this task, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boKVua9UmH8s"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE5ZGQ9yWhMk",
        "outputId": "89df03d9-3cc8-492f-9954-e2552b6c40b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzvqL1nTmH8s"
      },
      "source": [
        "### 2a. Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "Make sure to include the following in your model:\n",
        "- Add `1 dense layer` with a `single neuron` \n",
        "- Use a `sigmoid activation function`\n",
        "- Set `epochs` to 10 \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
        "---\n",
        "* Your model should be called `model1`. \n",
        "\n",
        "* The results of your fit model should be assigned to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "533f2731bf5c6bff190bfb764e02fada",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC2SsGqtmH8t",
        "outputId": "22fda64a-6c03-4cff-e12e-9325a2de68cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7325\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7306\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7291\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7277\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7266\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7254\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7242\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7231\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7219\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7208\n"
          ]
        }
      ],
      "source": [
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model1 = Sequential([\n",
        "    Dense(1, activation='sigmoid', input_dim=2),\n",
        "])\n",
        "model1.compile(loss='binary_crossentropy')\n",
        "h1 = model1.fit(X, y, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "408iDjKBmH8t"
      },
      "outputs": [],
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
        "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "EVko7lj6mH8t"
      },
      "outputs": [],
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idWzZO0jmH8t"
      },
      "source": [
        "### 2b. Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron model (also known as a neural network). \n",
        "\n",
        "Your neural network `must` have: \n",
        "- `2` Hidden Layers\n",
        "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `myCallback` function below into your model\n",
        "- Set epochs to `100`\n",
        "- Your model should be called `model2` \n",
        "- Save the results of your fit statement to a variable called `h2`. \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ad238f5d2d4fce7ec4b2bbeb786faf4e",
          "grade": false,
          "grade_id": "cell-eb88d895e6d9479d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "YFN6fvzWmH8u"
      },
      "outputs": [],
      "source": [
        "#do not delete or modify\n",
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        # if model reaches 99% accuracy, training is terminated \n",
        "        acc_threshold = 0.99\n",
        "        if(logs.get('accuracy') > acc_threshold):   \n",
        "            self.model.stop_training = True\n",
        "            self.model.callback_used = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWn7z0TKmH8u",
        "outputId": "5d735770-9e1c-4ae8-8685-0123e1c22dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4733\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.4733\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.4733\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.4733\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.4733\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.4733\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.4733\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.4733\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.4733\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.4733\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.4733\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.4733\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.4733\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.4733\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.4733\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.4733\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.4733\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.4733\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.4733\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.4733\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.4733\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.4733\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.4733\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.4733\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.4733\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.4733\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.4733\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.4733\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.4733\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.4733\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.4733\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.4733\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.4733\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.4733\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.4733\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.4733\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.4733\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.4733\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.4733\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.4733\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.4733\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.4733\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.4733\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.4733\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.4733\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.4733\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.4733\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.4733\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.4733\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.4733\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.4733\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.4733\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.4733\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.4733\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.4733\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.4733\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.4733\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.4733\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.4733\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.4733\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.4733\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.4733\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.4733\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.4733\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.4733\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.4733\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.4733\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.4733\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.4733\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.4733\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.4733\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.4733\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.4733\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.4733\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.4733\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.4733\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.4733\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.4733\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.4733\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.4733\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.4733\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.4733\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.4733\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.4733\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.4733\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.4733\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.4733\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.4733\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.4733\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.4733\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.4733\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.4733\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.4733\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.4733\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.4733\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.4733\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.4733\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.4733\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.4733\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.4733\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python import metrics\n",
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "callback = myCallback()\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(32, activation='sigmoid', input_dim=2))\n",
        "model2.add(Dense(16, activation='sigmoid'))\n",
        "model2.add(Dense(1, activation='softmax'))\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "               metrics=['accuracy'],\n",
        "               optimizer='adam')\n",
        "h2 = model2.fit(X, y, epochs=100, callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5f575f46f151f97f1cebc19a484bae",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zwjpNzptmH8u"
      },
      "outputs": [],
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
          "grade": true,
          "grade_id": "cell-49b1bf7cce22b5b9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gAHv7Z1FmH8u"
      },
      "outputs": [],
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b322042f3d8b515b4c5603946e355b13",
          "grade": false,
          "grade_id": "cell-f3490b86d4b284b0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ywzwoZHImH8u"
      },
      "source": [
        "### 2c. Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. \n",
        "\n",
        "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "You can install this package using the following statement in the terminal\n",
        "\n",
        "```python\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "Or you can install this package using the following statement in your notebook\n",
        "\n",
        "```python\n",
        "!pip install mlxtend\n",
        "```\n",
        "\n",
        "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "77f6f2a9a5839eeba03aabe273a272d0",
          "grade": false,
          "grade_id": "cell-40d69928751b50a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "Uy1PkTwWmH8u",
        "outputId": "c6d2ff69-c498-4d81-a2c8-9970c29ceda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11664/11664 [==============================] - 13s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9ef61bd383ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6115e8a53cd304ed19dcead4c4ebcaae",
          "grade": false,
          "grade_id": "cell-302694c508c8da0e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "E_eLkWEumH8u"
      },
      "source": [
        "#### Review\n",
        "1) Why does the Perceptron (model1) only achieve about 50% accuracy?\n",
        "\n",
        "A simple perceptron can only learn a linear decision boundary as seen in the visualization above. Since the data points are distributed in a way where only a single class is represented per quadrant, a linear decision boundary can never reach an accuracy much higher than about 50% since each class will be equally represented on either side of that linear decision boundary.\n",
        "\n",
        "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and Y?\n",
        "\n",
        "The additional layers and neurons allow a neural networks to learn non-linear relationships between X and Y. Each layer in a neural net represents an N-dimensional vector space. So by passing data from one layer to another, we are passing a data vector from one vector space to another, each with a different dimensions, often times this will change the geometry of the data points (i.e. their distribution in space) in such a way where a linear separation then becomes possible. This is the same idea behind the Kernel Trick in Support Vector Machines (SVM). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "54d26b93a7851569bb4b1b4800181af4",
          "grade": false,
          "grade_id": "cell-db1863a277e4fd6b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UFH0sy6nmH8v"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset provided (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyper-parameters tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "JeqlaL8OmH8v",
        "outputId": "f36a52d9-5a09-4865-a8c6-bedf691e9f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(303, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "19    69    0   3       140   239    0        1      151      0      1.8   \n",
              "210   57    1   2       128   229    0        0      150      0      0.4   \n",
              "68    44    1   1       120   220    0        1      170      0      0.0   \n",
              "243   57    1   0       152   274    0        1       88      1      1.2   \n",
              "249   69    1   2       140   254    0        0      146      0      2.0   \n",
              "\n",
              "     slope  ca  thal  target  \n",
              "19       2   2     2       1  \n",
              "210      1   1     3       0  \n",
              "68       2   0     2       1  \n",
              "243      1   1     3       0  \n",
              "249      1   3     3       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2eed78d5-0ca1-4fb7-bf50-d129b34c5b2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>140</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>274</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>88</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2eed78d5-0ca1-4fb7-bf50-d129b34c5b2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2eed78d5-0ca1-4fb7-bf50-d129b34c5b2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2eed78d5-0ca1-4fb7-bf50-d129b34c5b2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TbLu-3dZd8Hz",
        "outputId": "da6fdd91-5e50-4a49-bd34-72bf7c055205"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "19    69    0   3       140   239    0        1      151      0      1.8   \n",
              "210   57    1   2       128   229    0        0      150      0      0.4   \n",
              "68    44    1   1       120   220    0        1      170      0      0.0   \n",
              "243   57    1   0       152   274    0        1       88      1      1.2   \n",
              "249   69    1   2       140   254    0        0      146      0      2.0   \n",
              "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
              "277   57    1   1       124   261    0        1      141      0      0.3   \n",
              "3     56    1   1       120   236    0        1      178      0      0.8   \n",
              "135   49    0   0       130   269    0        1      163      0      0.0   \n",
              "121   59    1   0       138   271    0        0      182      0      0.0   \n",
              "302   57    0   1       130   236    0        0      174      0      0.0   \n",
              "\n",
              "     slope  ca  thal  \n",
              "19       2   2     2  \n",
              "210      1   1     3  \n",
              "68       2   0     2  \n",
              "243      1   1     3  \n",
              "249      1   3     3  \n",
              "..     ...  ..   ...  \n",
              "277      2   0     3  \n",
              "3        2   0     2  \n",
              "135      2   0     2  \n",
              "121      2   0     2  \n",
              "302      1   1     2  \n",
              "\n",
              "[303 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b1f32df-7d9f-48c6-8978-f92bd8b29c26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>140</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>274</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>88</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>124</td>\n",
              "      <td>261</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>269</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>271</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b1f32df-7d9f-48c6-8978-f92bd8b29c26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b1f32df-7d9f-48c6-8978-f92bd8b29c26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b1f32df-7d9f-48c6-8978-f92bd8b29c26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O96wDODHd58",
        "outputId": "21fa55ef-0631-4895-a5b0-7e47c5d173e6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2g9xE_CKmH8v"
      },
      "outputs": [],
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "\n",
        "# YOUR CODE HERE\n",
        "X = df[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]\n",
        "Y = df.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZrQKg4F9mH8v"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "vVeLzo1WHfAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "XwDs6urEmH8v"
      },
      "outputs": [],
      "source": [
        "# Create a function named 'create_model' that returns a complied keras model -  required for KerasClassifier\n",
        "# YOUR CODE HERE\n",
        "def create_model(input_dim=13, optimizer='adam', activation='sigmoid'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation=activation, input_dim=input_dim))\n",
        "  model.add(Dense(8, activation=activation))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "14fafb133c4cbe053b272ae08156e2ab",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "v9x6hZRAmH8v"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert (create_model().__module__ == 'tensorflow.python.keras.engine.sequential') or (create_model().__module__ == 'keras.engine.sequential'), \"create_model should return a keras model that was created using the Sequential class.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxQn9pcnmH8v",
        "outputId": "de1aa520-a3ec-47c0-c39d-06b99f896d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a4ad384196bf>:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model)\n"
          ]
        }
      ],
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "# YOUR CODE HERE\n",
        "model = KerasClassifier(build_fn=create_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b9a0fd482352443a412e7fdb13f5bae",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2UvDhQFNmH8v"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn' or model.__module__== 'keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "UUb8982ZmH8v"
      },
      "outputs": [],
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with 2 possible values for each \n",
        "\n",
        "# YOUR CODE HERE\n",
        "param_grid = {\n",
        "    \"batch_size\" : [32,16],\n",
        "    'epochs' : [50,100]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5W9e9EOrmH8v"
      },
      "outputs": [],
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8qMO012mH8w",
        "outputId": "8725c382-09db-4b29-a889-4e2da31992b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.4793\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5537\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5537\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5537\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5537\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5537\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5537\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.5579\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.5537\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.5537\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.5537\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.5537\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.5826\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.5950\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6033\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6033\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5950\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6033\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6116\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6240\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6281\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6240\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6364\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6570\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6612\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6653\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6612\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6612\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6570\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.6736\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6777\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6653\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6405\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6529\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6570\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6942\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6570\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6694\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6777\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.7025\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.6777\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6983\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.7190\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7149\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7066\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.7149\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.7107\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7066\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7190\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.7273\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.7377\n",
            "[CV] END ...........................batch_size=32, epochs=50; total time=   3.3s\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.5413\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7060 - accuracy: 0.5413\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.5413\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5413\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5413\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5413\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.5413\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5413\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.5413\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5413\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5413\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.5413\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.5413\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.5413\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.5413\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.5372\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.5537\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5992\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6322\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6653\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6777\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6612\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6694\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6653\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6653\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6653\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6777\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.6777\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6777\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6777\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6860\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6860\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6983\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6736\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6818\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6901\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7025\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6983\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.7025\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6983\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6983\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7066\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7107\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7107\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.7107\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.7149\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.7149\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.7149\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7066\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.7066\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.7213\n",
            "[CV] END ...........................batch_size=32, epochs=50; total time=   3.2s\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7369 - accuracy: 0.4669\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.4669\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.4669\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.4669\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.4669\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5785\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5579\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5413\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5372\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5455\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5413\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5413\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5413\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5496\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5620\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.6074\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.6033\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6074\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6074\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.6116\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.6116\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.6033\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.6033\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6033\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.6033\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.5992\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.5950\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.6033\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.5992\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.6033\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.6033\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.5992\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.5909\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5992\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6116\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6322\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6612\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.6777\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6694\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6364\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6860\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6777\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6612\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6694\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6694\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6529\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6529\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6818\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6488\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6777\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6564 - accuracy: 0.6230\n",
            "[CV] END ...........................batch_size=32, epochs=50; total time=   3.2s\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8254 - accuracy: 0.5267\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7954 - accuracy: 0.5267\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7714 - accuracy: 0.5267\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7538 - accuracy: 0.5267\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7408 - accuracy: 0.5267\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.5267\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7208 - accuracy: 0.5267\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7133 - accuracy: 0.5267\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7080 - accuracy: 0.5267\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.5267\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6989 - accuracy: 0.5267\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5267\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5267\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5267\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5267\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5267\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5267\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5267\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5267\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.5267\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5267\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5267\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.5267\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.5267\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5267\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5267\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.5267\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5267\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.5267\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5267\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5267\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5267\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5267\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5267\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5267\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.5267\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.5267\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.5267\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5267\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.5267\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.5267\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.5267\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.5267\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.5267\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.5267\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.5267\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.5267\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.5267\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.5267\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.5267\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6504 - accuracy: 0.6167\n",
            "[CV] END ...........................batch_size=32, epochs=50; total time=   3.3s\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 0.8055 - accuracy: 0.4321\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7692 - accuracy: 0.4321\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.4321\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.4321\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7167 - accuracy: 0.4321\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.4321\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.4321\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4321\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.4321\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.6379\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6667\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.6708\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.6831\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6749\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.6914\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.6872\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6708\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.6543\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.6461\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6502\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.6502\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.6831\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6955\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6914\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6914\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6914\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6914\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6914\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6996\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6996\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.7037\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6996\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.6996\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.7078\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.7078\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7160\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.7078\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.7078\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7160\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.7160\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.7202\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.7366\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.7160\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7325\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.7284\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.7243\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.7119\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.7119\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7202\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff62f601c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.6667\n",
            "[CV] END ...........................batch_size=32, epochs=50; total time=   2.5s\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5537\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5537\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5537\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5537\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5537\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5537\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5537\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5537\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5537\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5537\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5537\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.5537\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5537\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5537\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5537\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5537\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5537\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.5537\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5537\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.5537\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.5744\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6074\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6116\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.6116\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6074\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5992\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.6033\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6074\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.6033\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6074\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6116\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6157\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6198\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6322\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6446\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6488\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6446\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6446\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6364\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6116\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6157\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6157\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6240\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6198\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6281\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6240\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6405\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6488\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6488\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6446\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6446\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6529\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6488\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6653\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6612\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6818\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6860\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6860\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6983\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6901\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6045 - accuracy: 0.6777\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6028 - accuracy: 0.6818\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6002 - accuracy: 0.6901\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5990 - accuracy: 0.6860\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5982 - accuracy: 0.6983\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6983\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.7107\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5901 - accuracy: 0.6942\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7025\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7149\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7107\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7025\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7231\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.6901\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7107\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7149\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7231\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7397\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7190\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7314\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7314\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7355\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7397\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7314\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7355\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7521\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7355\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5465 - accuracy: 0.7479\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7397\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7438\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7355\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5396 - accuracy: 0.7479\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7479\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7479\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7521\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7438\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7438\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7479\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7397\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff62f7b7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5756 - accuracy: 0.7049\n",
            "[CV] END ..........................batch_size=32, epochs=100; total time=   4.1s\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 0.7196 - accuracy: 0.5413\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.5413\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.5413\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5413\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5413\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5413\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5413\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5413\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5413\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.5413\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.5413\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5413\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.5413\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5455\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.5496\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.5579\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.5579\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.5579\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.5661\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.5661\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.5785\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5785\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.5744\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.5909\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5950\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.5950\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6074\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.5992\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.5992\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6322\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6405\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6446\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6446\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6488\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6570\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6529\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6653\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.6818\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6860\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6818\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6860\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6860\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6942\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6694\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6818\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6694\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6901\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6942\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6777\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6777\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6942\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6942\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6942\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6901\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6860\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.6860\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6818\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6818\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6942\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.6942\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.7025\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6983\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6983\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6942\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6901\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.7107\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7025\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.6983\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6983\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7149\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6901\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6942\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7066\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.6983\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6942\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7107\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7231\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7066\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.6942\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.6901\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7025\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7314\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7149\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.6942\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7025\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.6983\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7314\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7314\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7314\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7273\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7355\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7479\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7397\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7355\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7355\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7438\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7314\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7397\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7397\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7438\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7705\n",
            "[CV] END ..........................batch_size=32, epochs=100; total time=   6.1s\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8011 - accuracy: 0.5331\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7680 - accuracy: 0.5331\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7419 - accuracy: 0.5331\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.5331\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.5331\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5331\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5331\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5331\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5331\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.5331\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.5331\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.5455\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6033\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.6116\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.6157\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6116\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6116\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6116\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6198\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6198\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6364\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6529\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.6612\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6446\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6405\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6529\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6736\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6736\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6942\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6736\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6942\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6942\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6860\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6942\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6942\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6942\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6942\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.7025\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.7025\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.7025\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6983\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7025\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6942\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6942\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6983\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6942\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.6942\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.7025\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.7107\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6942\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.6942\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.7107\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.7190\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7025\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.7066\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7273\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7025\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7066\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7107\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7149\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7025\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7066\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7025\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7149\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7231\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7190\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7190\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7231\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7107\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7107\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7149\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7190\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7231\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7190\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7149\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7231\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7149\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7190\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7314\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7190\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7231\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7190\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7231\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7231\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7273\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7149\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7231\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7314\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7355\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7231\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7314\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7273\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7231\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7231\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7231\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7479\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7355\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7314\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7314\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7273\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5393 - accuracy: 0.7541\n",
            "[CV] END ..........................batch_size=32, epochs=100; total time=   3.5s\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7002 - accuracy: 0.4733\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5103\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.6296\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6337\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6461\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.6543\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6790\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6914\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.6914\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.6872\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6831\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6831\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6831\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6872\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6914\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6996\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6996\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.7037\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6914\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7037\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6914\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.7078\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.7119\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6996\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.7037\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6790\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.6872\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.6831\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.6996\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7243\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7160\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7078\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7202\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7160\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7202\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7243\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7243\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7202\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7325\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7366\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7325\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7243\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7325\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7284\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7325\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7366\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7407\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7325\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7325\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7449\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7490\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7325\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7366\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7449\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7449\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7490\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7490\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7449\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7449\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7531\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7490\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7449\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7572\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7572\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7490\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7449\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7531\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7449\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7531\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7407\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7407\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7572\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7531\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7572\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7531\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7449\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7531\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7572\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7572\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7572\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7490\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7490\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7572\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7490\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7449\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7572\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7654\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7490\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7490\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7613\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7654\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7613\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7531\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7531\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7572\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7613\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7695\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7737\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7613\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7654\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.7000\n",
            "[CV] END ..........................batch_size=32, epochs=100; total time=   5.8s\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5679\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5679\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.5679\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6763 - accuracy: 0.5679\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.5679\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5679\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.5679\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.5679\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.5679\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.5679\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.5679\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.5679\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.5679\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.5679\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.5679\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.5679\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.5679\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.5679\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6132\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.6708\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6626\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6872\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6955\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6955\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.6914\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6996\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.7119\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6914\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6872\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7078\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.7160\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6996\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6955\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6955\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6955\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.7078\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7160\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7160\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7119\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7119\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7119\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7119\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7202\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7119\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.7202\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7119\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7243\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7243\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7119\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7160\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7202\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7202\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7243\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7243\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7366\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7407\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7284\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7366\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7325\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7407\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7407\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7366\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7325\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7366\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7366\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7407\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7325\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7407\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7449\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7531\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7407\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7407\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7407\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7449\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7490\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7490\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7531\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7613\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7449\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5262 - accuracy: 0.7449\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7490\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7572\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7613\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7531\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7531\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5161 - accuracy: 0.7613\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5130 - accuracy: 0.7490\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.7531\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7572\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7490\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5060 - accuracy: 0.7654\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5094 - accuracy: 0.7572\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7572\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5046 - accuracy: 0.7695\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7613\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4966 - accuracy: 0.7695\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4965 - accuracy: 0.7572\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7613\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7695\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.7654\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4957 - accuracy: 0.8000\n",
            "[CV] END ..........................batch_size=32, epochs=100; total time=   4.8s\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.7086 - accuracy: 0.5537\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5537\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.5537\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5537\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.5537\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5537\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.5537\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5579\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5620\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.5620\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5579\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6607 - accuracy: 0.6116\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.6116\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.6653\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6570\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6570\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6736\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6570\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7025\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6901\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6983\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.6942\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6295 - accuracy: 0.6983\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6252 - accuracy: 0.7314\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6217 - accuracy: 0.7355\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6194 - accuracy: 0.6983\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.6138 - accuracy: 0.7025\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.6105 - accuracy: 0.7314\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.6901\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.7355\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7273\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7190\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.7190\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7314\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7314\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.7479\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7273\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7397\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7273\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7438\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7355\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7231\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7273\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7355\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7397\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7314\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7314\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7438\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7397\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7355\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.6885\n",
            "[CV] END ...........................batch_size=16, epochs=50; total time=   5.1s\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.7018 - accuracy: 0.4711\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.6322\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.6653\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6240\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.5950\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.5785\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.5702\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6860\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.7066\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6942\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6488\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6983\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6860\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6901\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6983\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.7025\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.6983\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6777\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6901\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6818\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.7066\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.7107\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.7025\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6777\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7149\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.7107\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.7066\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.7190\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6942\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.7231\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.7107\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7231\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7107\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.7190\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7149\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7231\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.7273\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7025\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7107\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7273\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7314\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7231\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7355\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7231\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7231\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7190\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7231\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7273\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7314\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7025\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.7377\n",
            "[CV] END ...........................batch_size=16, epochs=50; total time=   3.3s\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7450 - accuracy: 0.5331\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.5331\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.5331\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5331\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5331\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5331\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5331\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.5331\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.5372\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.5372\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.5372\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.5744\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5950\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6074\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.6364\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6488\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6281\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6612\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6488\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6942\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6818\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.7149\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6818\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6983\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.6694\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.7107\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.7066\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.7231\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.7273\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6901\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7314\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.7355\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.7397\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.7397\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.7231\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.7231\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.7438\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.7438\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.7479\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.7397\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7231\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7397\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7355\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7521\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7521\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7479\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7603\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7438\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7521\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7521\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7377\n",
            "[CV] END ...........................batch_size=16, epochs=50; total time=   3.0s\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.5267\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5267\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5267\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5267\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.5267\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.5432\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6790\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6584\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6584\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6708\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6914\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6831\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6749\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6708\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6708\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6872\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6708\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6872\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6790\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6955\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6955\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.7037\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6914\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.7243\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.7243\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.7078\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.7202\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.7078\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7366\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.7284\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7284\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7119\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7160\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7366\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7407\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7325\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7366\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7243\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7243\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7407\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7407\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7490\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7449\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7366\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7243\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7243\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7449\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7531\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7407\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7531\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6667\n",
            "[CV] END ...........................batch_size=16, epochs=50; total time=   3.0s\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.6132\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.5720\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.5720\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.5802\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.5761\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.5844\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6255\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6173\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6296\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6337\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6337\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.6461\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6543\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6584\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6626\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6337\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6543\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6667\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6626\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6502\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6461\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6749\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6584\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.6749\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.6831\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6996\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6790\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7078\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.7078\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6955\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.6955\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.6914\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7119\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7243\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7160\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7243\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7202\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7243\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7202\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7366\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7284\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7160\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7284\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7243\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7284\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7284\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7284\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7284\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7325\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7333\n",
            "[CV] END ...........................batch_size=16, epochs=50; total time=   3.1s\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.6981 - accuracy: 0.4545\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5992\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5537\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5537\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.5579\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5702\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6281\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.6653\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6364\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6364\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.5702\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.5992\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6488\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6612\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6777\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6901\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6777\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6860\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6942\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6612\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6777\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6860\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6901\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7066\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.7190\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.7025\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6901\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.7066\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7107\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6901\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.7025\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7107\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7355\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7231\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7190\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7149\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7355\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7066\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7273\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7273\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7190\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7314\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7273\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7231\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7314\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7314\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7397\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7355\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7314\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7397\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7314\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7479\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7355\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7397\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7521\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7479\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7314\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7397\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7603\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7397\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7479\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7397\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7438\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7438\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7397\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7521\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7438\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7438\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7603\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7479\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7562\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7438\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7603\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7397\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7562\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7438\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7603\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7686\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7645\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7645\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7521\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7562\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7727\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7479\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7562\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7769\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7645\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7562\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7603\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7810\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7727\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7645\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7727\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7645\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7645\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7727\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7727\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7686\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7603\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7727\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.6885\n",
            "[CV] END ..........................batch_size=16, epochs=100; total time=   5.3s\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.7744 - accuracy: 0.4587\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7215 - accuracy: 0.4587\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.4587\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.4587\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5124\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6653\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6364\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6364\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6446\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6446\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6653\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6570\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6612\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6570\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6529\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6612\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6612\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6570\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6736\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.6653\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6612\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6694\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6612\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6777\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6818\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6818\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.6570\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6777\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6860\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6818\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6570\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6818\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.6860\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.6777\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6860\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6818\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7025\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6942\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6860\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6777\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6983\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6942\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6860\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7025\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.6942\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7066\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.6942\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.6983\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6901\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7149\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7149\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7190\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7107\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7149\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7066\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7190\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7397\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7397\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7149\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7107\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7562\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7273\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7314\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7355\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7397\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7149\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7521\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7479\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7397\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7355\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7355\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7603\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7355\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7479\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7603\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7438\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7438\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7562\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7521\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7521\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7479\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7562\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7645\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7645\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7603\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7645\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7727\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7562\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7810\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7645\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7686\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7810\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7603\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7893\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7727\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7686\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7769\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7810\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7851\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7769\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8525\n",
            "[CV] END ..........................batch_size=16, epochs=100; total time=   6.0s\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.4669\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.4669\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4669\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.4669\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.4752\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.6033\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.6736\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6653\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5496\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5496\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.5496\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.5496\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5455\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5496\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5992\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.6074\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.5579\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.5579\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5455\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.6364\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.6198\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6322\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6198\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.6694\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.6860\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6942\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.6818\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.6942\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6942\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6818\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.7066\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6983\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6983\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6983\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.7149\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.7107\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7025\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.7107\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.7149\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.7107\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.7066\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7231\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.7190\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.7190\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.7231\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6942\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7231\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.7355\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.7149\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.7190\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.7107\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.7397\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7273\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.7314\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7231\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7314\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.7355\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.7149\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.7231\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.7355\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7479\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7314\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7355\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7314\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7355\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7231\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7438\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7438\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7438\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7479\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7397\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7521\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7273\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7438\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7521\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7603\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7562\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7521\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7686\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7562\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7521\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7562\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7603\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7769\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7851\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7727\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7727\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7727\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7603\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7686\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7769\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7686\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7810\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7686\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7810\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7810\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7810\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7851\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7851\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8017\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.8197\n",
            "[CV] END ..........................batch_size=16, epochs=100; total time=   5.8s\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.7154 - accuracy: 0.5267\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.5267\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5267\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5267\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.5885\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.6214\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.6091\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6296\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6626\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6996\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.7243\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.7243\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.7366\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7366\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.7407\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7160\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.7202\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6996\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.7037\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6955\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.7160\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.7119\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7202\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.7243\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6996\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.7202\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6955\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7366\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.7325\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7078\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7284\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.7202\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7325\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7284\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7407\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7284\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7449\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7284\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7490\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7160\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7407\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7325\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7366\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7449\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7490\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7366\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7407\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7366\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7366\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7202\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7407\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7572\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7449\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7366\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7531\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7366\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7407\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7490\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7407\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7531\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7613\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7531\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7531\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7490\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7449\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7572\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7572\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7407\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7407\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7572\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7654\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7490\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7531\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7366\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7737\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7695\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7613\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7490\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7531\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7778\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7695\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7572\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7695\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7819\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7654\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7613\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7654\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7737\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7613\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7572\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7778\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7737\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7654\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7819\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7737\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7695\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7695\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7737\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7778\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7819\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.6667\n",
            "[CV] END ..........................batch_size=16, epochs=100; total time=   5.8s\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.6853 - accuracy: 0.5679\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5679\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.5679\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5679\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5679\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.5679\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5679\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5679\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.5679\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.5679\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.5679\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5679\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5597\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.5761\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6091\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6296\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6379\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6337\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.5844\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.5802\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6420\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6420\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6543\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6502\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6502\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6255\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6461\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.6667\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.6626\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6502\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6379\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6502\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6502\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6626\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6502\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6461\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6584\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6420\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6543\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6502\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6708\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6831\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6626\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6831\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6790\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6790\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.6872\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6831\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6790\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6914\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6872\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6831\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6831\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6708\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6872\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6914\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6996\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6996\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.7037\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6955\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6831\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.6914\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6790\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.6790\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6872\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6914\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6996\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6996\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6955\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6996\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7119\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6955\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7119\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7119\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6996\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6996\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7160\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7078\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7284\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7325\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7119\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7078\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7119\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7119\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7160\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7119\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7202\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7160\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7202\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7202\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7202\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7243\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7202\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7366\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7407\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7284\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7407\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7366\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7243\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.6333\n",
            "[CV] END ..........................batch_size=16, epochs=100; total time=   6.1s\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7168 - accuracy: 0.5446\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.5446\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5446\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5446\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5446\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.5479\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5644\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5809\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5908\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.5710\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5710\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6205\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6568\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6733\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6865\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.6832\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.7129\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7195\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6898\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6964\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7195\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7261\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.7129\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.7195\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.7228\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7294\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7228\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7294\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7129\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7294\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.7195\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7294\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7261\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7195\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.7261\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7261\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7228\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7261\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.7294\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7294\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7327\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7195\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7261\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7360\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7360\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7294\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7294\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7294\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7327\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7327\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7294\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7327\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7360\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7294\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7327\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7294\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7327\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7327\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7360\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7327\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7360\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7492\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7393\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7393\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7393\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7327\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7393\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7426\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7327\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7492\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7426\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7393\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7459\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7459\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7459\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7426\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7426\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7492\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7459\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7492\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7558\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7492\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7492\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7492\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7459\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7591\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7558\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7525\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7591\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7459\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7657\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7558\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7591\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7558\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7558\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7591\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7558\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7591\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7492\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7624\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import gridspec\n",
        "# Create Grid Search object and name it 'gs'\n",
        "# Run Grid Search \n",
        "# YOUR CODE HERE\n",
        "gs = GridSearchCV(estimator=model,\n",
        "                  param_grid=param_grid,\n",
        "                  n_jobs=1,\n",
        "                  verbose=2)\n",
        "grid_result = gs.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "oKykOFZzmH8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73da03d-8b0f-428d-ffbb-8f5dccb786f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.74590163230896 using {'batch_size': 32, 'epochs': 100}\n",
            "Means: 0.6730601072311402, Stdev: 0.04947561833904648 with: {'batch_size': 32, 'epochs': 50}\n",
            "Means: 0.74590163230896, Stdev: 0.03843205202021592 with: {'batch_size': 32, 'epochs': 100}\n",
            "Means: 0.7127869009971619, Stdev: 0.029596305130762928 with: {'batch_size': 16, 'epochs': 50}\n",
            "Means: 0.7321311473846436, Stdev: 0.08728155703546953 with: {'batch_size': 16, 'epochs': 100}\n"
          ]
        }
      ],
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}